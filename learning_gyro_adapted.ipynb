{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50dcc865-d26d-452e-8e9f-353bb4c88ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a1f43-6314-42d9-bf81-424bee5b72e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bshuf filter already loaded, skip it.\n",
      "2022-04-08 16:33:25.211887: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-08 16:33:25.214540: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-04-08 16:33:25.214579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7860 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:18:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 16:33:28.337007: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 37s 321ms/step - loss: 52466940.0000\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 33s 328ms/step - loss: 36556.6016\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 34s 336ms/step - loss: 704.6519\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 32s 315ms/step - loss: 987.9020\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 636.0269\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 33s 327ms/step - loss: 4.7951\n",
      "Epoch 7/100\n",
      " 92/100 [==========================>...] - ETA: 2s - loss: 1714.3676"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "\n",
    "import examplesetup\n",
    "import lib.deconvolution as deconvolution\n",
    "import lib.utils as utils\n",
    "import lib.xtrace as xtrace\n",
    "import lib.datagen as datagen\n",
    "import lib.mlmodels as mlmodels\n",
    "\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "keras.backend.clear_session()\n",
    "\n",
    "img_shape = (100, 100)\n",
    "batch_size = 32\n",
    "batches = 100\n",
    "\n",
    "# Build model\n",
    "models = mlmodels.modelsClass(*img_shape)\n",
    "model = models.getDeepBlind()\n",
    "#model.summary()\n",
    "train_gen = datagen.SyntheticDepthBlur(batch_size, batches, img_shape)\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss=tf.keras.losses.MeanSquaredError())\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"trained_networks/deconvolve.h5\", monitor=\"loss\", save_best_only=True)\n",
    "]\n",
    "\n",
    "epochs = 100\n",
    "model.fit(train_gen, epochs=epochs, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a01f10-6c2f-4459-82a4-15324cda70ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Test combinations:\n",
    "# With/without image noise in training\n",
    "# With/without changing pixel hit position\n",
    "# With/without chaning config parameters\n",
    "# deepBlind/DeepGyro with extra data\n",
    "#\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "model = n\n",
    "img = image.imread(\"example_files/example_image.png\").sum(axis=2)\n",
    "distorted_img, img = datagen.get_synthetic_data_pair(img_shape, G=G_glob)\n",
    "recovered_img = model(distorted_img[np.newaxis,:,:], training=False).numpy()[0,:,:,0]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 10), sharex=True, sharey=True)\n",
    "perc = np.percentile(distorted_img, 99)\n",
    "axs[0].imshow(img, vmax=perc, vmin=0)\n",
    "axs[1].imshow(distorted_img,  vmax=perc, vmin=0)\n",
    "axs[2].imshow(recovered_img,  vmax=perc, vmin=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HDF5 / Simple Analysis / GPU",
   "language": "python",
   "name": "maxiv-jhub-docker-kernel-hdf5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
