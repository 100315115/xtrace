{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50dcc865-d26d-452e-8e9f-353bb4c88ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f97502c-632d-4cb1-aa13-aa8e17c16cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bshuf filter already loaded, skip it.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "\n",
    "import examplesetup\n",
    "import lib.deconvolution as deconvolution\n",
    "import lib.utils as utils\n",
    "import lib.xtrace as xtrace\n",
    "import lib.datagen as datagen\n",
    "\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img_shape = (100, 100)\n",
    "\n",
    "class SyntheticDepthBlur(keras.utils.Sequence):\n",
    "\n",
    "    #could include options to configure config params (or there ranges)\n",
    "    def __init__(self, batch_size, batches, img_shape):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_shape = img_shape\n",
    "        self.batches = batches\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batches\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        data = np.array([\n",
    "            datagen.get_synthetic_data_pair()\n",
    "            for i in range(self.batch_size)\n",
    "        ])\n",
    "        distorted_imgs = data[:,0, :, :, np.newaxis]\n",
    "        images = data[:,1, :, :, np.newaxis]\n",
    "        return (distorted_imgs, images)\n",
    "\n",
    "#test = SyntheticDepthBlur(50, 5, (100, 100))\n",
    "#v = test[0]\n",
    "#plt.imshow(v[1][0,:,:,0])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23e8f513-bcf9-4d07-b32b-28658a0072df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, Conv2DTranspose, MaxPooling2D, ZeroPadding2D\n",
    "from keras import backend as keras_backend\n",
    "\n",
    "class modelsClass(object):\n",
    "\n",
    "    def __init__(self, img_rows = 272, img_cols = 480):\n",
    "\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "\n",
    "    def addPadding(self, layer, level): #height, width, level):\n",
    "    \n",
    "        w1, h1 = self.img_cols, self.img_rows\n",
    "        w2, h2 = int(w1/2), int(h1/2)\n",
    "        w3, h3 = int(w2/2), int(h2/2)\n",
    "        w4, h4 = int(w3/2), int(h3/2)\n",
    "        h = [h1,h2,h3,h4]\n",
    "        w = [w1,w2,w3,w4]\n",
    "        \n",
    "        # Target width and height\n",
    "        tw = w[level-1]\n",
    "        th = h[level-1]\n",
    "        \n",
    "        # Source width and height\n",
    "        lsize = keras_backend.int_shape(layer)\n",
    "        sh = lsize[1]\n",
    "        sw = lsize[2]\n",
    "\n",
    "        pw = (0, tw - sw)\n",
    "        ph = (0, th - sh)\n",
    "\n",
    "        layer = ZeroPadding2D(padding=(ph,pw),data_format=\"channels_last\")(layer)\n",
    "    \n",
    "        return layer\n",
    "        \n",
    "    def getDeepGyro(self):\n",
    "\n",
    "        input_blurred = Input((self.img_rows, self.img_cols,1))\n",
    "        input_blurx = Input((self.img_rows, self.img_cols,1))\n",
    "        input_blury = Input((self.img_rows, self.img_cols,1))\n",
    "        \n",
    "        inputs = concatenate([input_blurred,input_blurx,input_blury])\n",
    "        \n",
    "        conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "        conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "        conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "        conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "        conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "        conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "        conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
    "        conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "        conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n",
    "        conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "        up6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
    "        up6 = self.addPadding(up6,level=4)\n",
    "        up6 = concatenate([up6,conv4], axis=3)\n",
    "        conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(up6)\n",
    "        conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "        up7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "        up7 = self.addPadding(up7,level=3)\n",
    "        up7 = concatenate([up7,conv3], axis=3)\n",
    "        conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(up7)\n",
    "        conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "        up8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "        up8 = self.addPadding(up8,level=2)\n",
    "        up8 = concatenate([up8,conv2], axis=3)\n",
    "        conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(up8)\n",
    "        conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "        up9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "        up9 = self.addPadding(up9,level=1)\n",
    "        up9 = concatenate([up9,conv1], axis=3)\n",
    "        conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(up9)\n",
    "        conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "        conv10 = Conv2D(3, (1, 1), activation='linear')(conv9)\n",
    "        \n",
    "        model = Model(inputs=[input_blurred,input_blurx,input_blury], outputs=conv10)\n",
    "           \n",
    "        #adam = optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        #model.compile(optimizer = adam, loss = 'mean_squared_error')\n",
    "\n",
    "        return model\n",
    "        \n",
    "    def getDeepBlind(self):\n",
    "\n",
    "        input_blurred = Input((self.img_rows, self.img_cols,1))\n",
    "        \n",
    "        m = 1\n",
    "        conv1 = Conv2D(64*m, (3, 3), activation='relu', padding='same')(input_blurred)\n",
    "        conv1 = Conv2D(64*m, (3, 3), activation='relu', padding='same')(conv1)\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "        conv2 = Conv2D(128*m, (3, 3), activation='relu', padding='same')(pool1)\n",
    "        conv2 = Conv2D(128*m, (3, 3), activation='relu', padding='same')(conv2)\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "        conv3 = Conv2D(256*m, (3, 3), activation='relu', padding='same')(pool2)\n",
    "        conv3 = Conv2D(256*m, (3, 3), activation='relu', padding='same')(conv3)\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "        conv4 = Conv2D(512*m, (3, 3), activation='relu', padding='same')(pool3)\n",
    "        conv4 = Conv2D(512*m, (3, 3), activation='relu', padding='same')(conv4)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "        conv5 = Conv2D(1024*m, (3, 3), activation='relu', padding='same')(pool4)\n",
    "        conv5 = Conv2D(1024*m, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "        up6 = Conv2DTranspose(512*m, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
    "        up6 = self.addPadding(up6,level=4)\n",
    "        up6 = concatenate([up6,conv4], axis=3)\n",
    "        conv6 = Conv2D(512*m, (3, 3), activation='relu', padding='same')(up6)\n",
    "        conv6 = Conv2D(512*m, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "        up7 = Conv2DTranspose(256*m, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "        up7 = self.addPadding(up7,level=3)\n",
    "        up7 = concatenate([up7,conv3], axis=3)\n",
    "        conv7 = Conv2D(256*m, (3, 3), activation='relu', padding='same')(up7)\n",
    "        conv7 = Conv2D(256*m, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "        up8 = Conv2DTranspose(128*m, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "        up8 = self.addPadding(up8,level=2)\n",
    "        up8 = concatenate([up8,conv2], axis=3)\n",
    "        conv8 = Conv2D(128*m, (3, 3), activation='relu', padding='same')(up8)\n",
    "        conv8 = Conv2D(128*m, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "        up9 = Conv2DTranspose(64*m, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "        up9 = self.addPadding(up9,level=1)\n",
    "        up9 = concatenate([up9,conv1], axis=3)\n",
    "        conv9 = Conv2D(64*m, (3, 3), activation='relu', padding='same')(up9)\n",
    "        conv9 = Conv2D(64*m, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "        conv10 = Conv2D(1, (1, 1), activation='linear')(conv9)\n",
    "        \n",
    "        model = Model(inputs=input_blurred, outputs=conv10)\n",
    "        \n",
    "        #adam = optimizers.Adam(lr=0.0000125, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        #model.compile(optimizer = adam, loss = 'mean_squared_error')\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a1f43-6314-42d9-bf81-424bee5b72e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 15:24:12.677446: W tensorflow/core/framework/op_kernel.cc:1733] INVALID_ARGUMENT: ValueError: Could not find callback with key=pyfunc_2 in the registry.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/conda/envs/hdf5-kernel-environment/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 259, in __call__\n",
      "    raise ValueError(f\"Could not find callback with key={token} in the \"\n",
      "\n",
      "ValueError: Could not find callback with key=pyfunc_2 in the registry.\n",
      "\n",
      "\n",
      "2022-04-08 15:24:12.677507: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: INVALID_ARGUMENT: ValueError: Could not find callback with key=pyfunc_2 in the registry.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/conda/envs/hdf5-kernel-environment/lib/python3.9/site-packages/tensorflow/python/ops/script_ops.py\", line 259, in __call__\n",
      "    raise ValueError(f\"Could not find callback with key={token} in the \"\n",
      "\n",
      "ValueError: Could not find callback with key=pyfunc_2 in the registry.\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 35s 325ms/step - loss: 4250314.0000\n",
      "Epoch 2/500\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 1220741.3750\n",
      "Epoch 3/500\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 569960.4375\n",
      "Epoch 4/500\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 475592.1875\n",
      "Epoch 5/500\n",
      "100/100 [==============================] - 31s 312ms/step - loss: 25247692.0000\n",
      "Epoch 6/500\n",
      "100/100 [==============================] - 31s 313ms/step - loss: 555317.3125\n",
      "Epoch 7/500\n",
      "100/100 [==============================] - 32s 322ms/step - loss: 455616.1562\n",
      "Epoch 8/500\n",
      "100/100 [==============================] - 32s 325ms/step - loss: 445349.7500\n",
      "Epoch 9/500\n",
      "100/100 [==============================] - 31s 313ms/step - loss: 3415954.0000\n",
      "Epoch 10/500\n",
      "100/100 [==============================] - 31s 312ms/step - loss: 445936.4062\n",
      "Epoch 11/500\n",
      "100/100 [==============================] - 31s 313ms/step - loss: 4237675.5000\n",
      "Epoch 12/500\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 606492.8125\n",
      "Epoch 13/500\n",
      "100/100 [==============================] - 31s 313ms/step - loss: 1152032.3750\n",
      "Epoch 14/500\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 628629.8125\n",
      "Epoch 15/500\n",
      "100/100 [==============================] - 31s 312ms/step - loss: 446833.6875\n",
      "Epoch 16/500\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 447318.8438\n",
      "Epoch 17/500\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 457575.0000\n",
      "Epoch 18/500\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 558759.1875\n",
      "Epoch 19/500\n",
      "100/100 [==============================] - 31s 312ms/step - loss: 446164.9688\n",
      "Epoch 20/500\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 446686.6875\n",
      "Epoch 21/500\n",
      "100/100 [==============================] - 31s 312ms/step - loss: 3124420.2500\n",
      "Epoch 22/500\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 571070.7500\n",
      "Epoch 23/500\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 446436.7188\n",
      "Epoch 24/500\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 8636921.0000\n",
      "Epoch 25/500\n",
      "100/100 [==============================] - 31s 313ms/step - loss: 448492.1875\n",
      "Epoch 26/500\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 447295.8750\n",
      "Epoch 27/500\n",
      " 55/100 [===============>..............] - ETA: 14s - loss: 448045.5000"
     ]
    }
   ],
   "source": [
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "keras.backend.clear_session()\n",
    "\n",
    "batch_size = 32\n",
    "batches = 100\n",
    "\n",
    "# Build model\n",
    "models = modelsClass(*img_shape)\n",
    "model = models.getDeepBlind()\n",
    "#model.summary()\n",
    "train_gen = SyntheticDepthBlur(batch_size, batches, img_shape)\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss=tf.keras.losses.MeanAbsolutePercentageError())\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"trained_networks/deconvolve.h5\", monitor=\"loss\", save_best_only=True)\n",
    "]\n",
    "\n",
    "epochs = 500\n",
    "model.fit(train_gen, epochs=epochs, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a01f10-6c2f-4459-82a4-15324cda70ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Test combinations:\n",
    "# With/without image noise in training\n",
    "# With/without changing pixel hit position\n",
    "# With/without chaning config parameters\n",
    "# deepBlind/DeepGyro with extra data\n",
    "#\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "model = n\n",
    "img = image.imread(\"example_image.png\").sum(axis=2)\n",
    "distorted_img, img = datagen.get_synthetic_data_pair(img_shape, G=G_glob)\n",
    "recovered_img = model(distorted_img[np.newaxis,:,:], training=False).numpy()[0,:,:,0]\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 10), sharex=True, sharey=True)\n",
    "perc = np.percentile(distorted_img, 99)\n",
    "axs[0].imshow(img, vmax=perc, vmin=0)\n",
    "axs[1].imshow(distorted_img,  vmax=perc, vmin=0)\n",
    "axs[2].imshow(recovered_img,  vmax=perc, vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edb5b0f-4546-47bc-9b53-7d767cb06f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2984d127-0ff1-4169-b921-25e10dfa1b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HDF5 / Simple Analysis / GPU",
   "language": "python",
   "name": "maxiv-jhub-docker-kernel-hdf5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
